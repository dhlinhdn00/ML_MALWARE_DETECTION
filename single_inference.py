import argparse
import joblib
import numpy as np

def load_model(model_name):
    model_path = f"./models/{model_name}.joblib"
    try:
        model = joblib.load(model_path)
        print(f"Model {model_name} loaded from disk.")
        return model
    except FileNotFoundError:
        print(f"Model {model_name} not found. Please train and save the model first.")
        return None

def load_features_from_txt(file_path):
    features = {}
    with open(file_path, 'r') as file:
        for line in file:
            key, value = line.strip().split(': ')
            features[key] = float(value)
    return features

def prepare_single_data(features, feature_columns):
    data = []
    for col in feature_columns:
        data.append(features.get(col, 0.0))
    return np.array(data).reshape(1, -1)

def main():
    parser = argparse.ArgumentParser(description="Run inference on a single PE file features.")
    parser.add_argument('--model', choices=['random_forest', 'xgboost', 'knn', 'naive_bayes', 'lightgbm', 'catboost', 'simple_nn'], required=True, help='Specify which model to use for inference')
    parser.add_argument('--file', type=str, required=True, help='Path to the .txt file containing PE file features')
    args = parser.parse_args()

    # Load the trained model
    model = load_model(args.model)
    if model is None:
        return

    # Load features from the provided .txt file
    features = load_features_from_txt(args.file)

    # Define the feature columns based on your dataset
    feature_columns = [
        'Machine', 'SizeOfOptionalHeader', 'Characteristics', 'MajorLinkerVersion', 'MinorLinkerVersion',
        'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode',
        'BaseOfData', 'ImageBase', 'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion',
        'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion', 'MajorSubsystemVersion',
        'MinorSubsystemVersion', 'SizeOfImage', 'SizeOfHeaders', 'CheckSum', 'Subsystem', 'DllCharacteristics',
        'SizeOfStackReserve', 'SizeOfStackCommit', 'SizeOfHeapReserve', 'SizeOfHeapCommit', 'LoaderFlags',
        'NumberOfRvaAndSizes', 'SectionsNb', 'SectionsMeanEntropy', 'SectionsMinEntropy', 'SectionsMaxEntropy',
        'SectionsMeanRawsize', 'SectionsMinRawsize', 'SectionsMaxRawsize', 'SectionsMeanVirtualsize',
        'SectionsMinVirtualsize', 'SectionsMaxVirtualsize', 'ImportsNbDLL', 'ImportsNb', 'ImportsNbOrdinal',
        'ExportNb', 'ResourcesNb', 'ResourcesMeanEntropy', 'ResourcesMinEntropy', 'ResourcesMaxEntropy',
        'ResourcesMeanSize', 'ResourcesMinSize', 'ResourcesMaxSize', 'LoadConfigurationSize',
        'VersionInformationSize'
    ]

    # Prepare the data for inference
    data = prepare_single_data(features, feature_columns)

    # Perform inference
    prediction = model.predict(data)
    result = "Malware" if prediction == 1 else "Benign"
    print(f"The file is predicted to be: {result}")

if __name__ == "__main__":
    main()
