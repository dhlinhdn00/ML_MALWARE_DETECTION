import argparse
import time
from util import load_data, display_model_performance, prepare_data, scale_data, evaluate_model, perform_knn_cv
from model import random_forest, xgboost, knn, naive_bayes, lightgbm, catboost, simple_neural_network
import numpy as np
from sklearn.model_selection import cross_val_score
import joblib
import os

def save_model(model, model_name):
    joblib.dump(model, f"./models/{model_name}.joblib")
    print(f"Model saved as {model_name}.joblib")

def load_model(model_name):
    if os.path.exists(f"{model_name}.joblib"):
        model = joblib.load(f"./models/{model_name}.joblib")
        print(f"Model {model_name} loaded from disk")
        return model
    else:
        print(f"Model {model_name}.joblib not found. Please train the model first.")
        return None

def main():
    parser = argparse.ArgumentParser(description="Run ML models on PE files dataset")
    parser.add_argument('--model', choices=['random_forest', 'xgboost', 'knn', 'naive_bayes', 'lightgbm', 'catboost', 'simple_nn'], required=True, help='Specify which model to run')
    parser.add_argument('--save', action='store_true', help='Save the trained model to disk')
    parser.add_argument('--load', action='store_true', help='Load the model from disk and run inference')
    args = parser.parse_args()

    if args.load:
        model = load_model(args.model)
        if model is None:
            return
        dataset = load_data('./data/data.csv')
        _, X_test, _, y_test = prepare_data(dataset, ['Name', 'md5', 'legitimate'])
        _, X_test_scaled = scale_data(None, X_test)

        y_pred = model.predict(X_test_scaled)
        display_model_performance(y_test, y_pred, name=args.model)
    else:
        dataset = load_data('./data/data.csv')
        X_train, X_test, y_train, y_test = prepare_data(dataset, ['Name', 'md5', 'legitimate'])
        X_train_scaled, X_test_scaled = scale_data(X_train, X_test)

        start_time = time.time()

        if args.model == 'knn':
            optimal_k, knn_scores = perform_knn_cv(X_train_scaled, y_train)
            print(f"The optimal number of neighbors is {optimal_k}")
            model = knn(X_train_scaled, y_train, n_neighbors=optimal_k)
            y_pred = model.predict(X_test_scaled)
            scores = cross_val_score(model, X_train_scaled, y_train, cv=10)
            cv_mean = scores.mean()
            cv_std = scores.std()
        else:
            if args.model == 'simple_nn':
                input_dim = X_train_scaled.shape[1]
                model = simple_neural_network(input_dim)
                model.fit(X_train_scaled, y_train, epochs=50, validation_split=0.2, batch_size=32)
                
                scores = evaluate_model(lambda input_dim=input_dim: simple_neural_network(input_dim), X_train_scaled, y_train, epochs=10, batch_size=32)
                y_pred = (model.predict(X_test_scaled) > 0.5).astype("int32")
            else:
                model = eval(f"{args.model}")(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                scores = cross_val_score(estimator=model, X=X_train_scaled, y=y_train, cv=10)
            
            cv_mean = np.mean(scores)
            cv_std = np.std(scores)

        elapsed_time = time.time() - start_time 
        print(f"Elapsed time for {args.model}: {elapsed_time:.2f} seconds")

        display_model_performance(y_test, y_pred, cv_mean, cv_std, name=args.model)

        if args.save:
            save_model(model, args.model)

if __name__ == "__main__":
    main()
